<!doctype html>
<html lang="en">
	<head>
		<title>O'Reilly Introduction to WebRTC</title>
		<link rel="stylesheet" type="text/css" href="css/style.css">
	</head>
	<body>
		<div>
			Video:<select id="camera"></select>
		</div>
		<video id="videoTag"></video>
		<p><button id="takeProfilePicture" type="button" autofocus="true">Create Profile Picture</button></p>
		<canvas id="profilePicCanvas" style="display:none"></canvas>
		<div>
			<img id="profilePictureOutput">
		</div>
		<script>
			
			var videoArea=document.querySelector("video");
			var videoSelect=document.querySelector('#camera');

			var profilePicCanvas=document.querySelector("#profilePicCanvas");
			var profilePictureOutput=document.querySelector("#profilePictureOutput");
			var takePicButton=document.querySelector("#takeProfilePicture");
			var videoTag=document.querySelector("#videoTag");

			var width=240; //Desired width of the profile picture
			var height=0; //Calulated later base on image ratio
			var streaming=false; //Used to determine when the video has loaded
			var localStream;

			takePicButton.addEventListener('click',function(ev){
				takeProfilePic();
				ev.preventDefault();
			},false);

			videoTag.addEventListener('canplay',function(ev){
				console.log('video can play');
				if (!streaming)
				{
					height=videoTag.videoHeight/(videoTag.videoWidth/width);
					//height=videoTag.videoArea.Width/(videoTag.videoArea.Width/Width);
					//firefox currently has a bug where the height can't be read
					//the video , so we will make assumptions if this happens.

					if(isNaN(height))
					{
						height=width/(4/3);
					}

					videoTag.setAttribute('width',width);
					videoTag.setAttribute('height',height);
					profilePicCanvas.setAttribute('width',width);
					profilePicCanvas.setAttribute('height',height);
					streaming=true;
				}
			},false); 


			function takeProfilePic(){
				var context=profilePicCanvas.getContext('2d');
				if(window && height)
				{
					profilePicCanvas.width=width;
					profilePicCanvas.height=height;
					context.drawImage(videoTag,0,0,width,height);

					var data=profilePicCanvas.toDataURL('image/png');
					profilePictureOutput.setAttribute('src',data);
				}
			}

			//MediaStreamTrack.getSources(getCameras);
			if (typeof MediaStreamTrack=='undefine' || typeof MediaStreamTrack.enumerateDevices=='undefine'){
				document.querySelector('#camera').style.visibility="hidden";
			}
			else
			{
				getCameras();
			}
		
			
			videoSelect.onchange=function(){
				console.log('onchange '+videoSelect.value);
				startStream();
			}

			//startStream();

			async function startStream()
			{
				
				//navigator.getUserMedia=navigator.getUserMedia||navigator.webkitGetUseerMedia||navigator.mozGetUserMedia;
				
				var videoSource=videoSelect.value;
				console.log('videoSelect.value: '+videoSelect.value);
				var constraints={
					audio:true,
					video:{
						/*mandatory:{
							minWidth:240,
							maxWidth:240,
							minHeight:360,
							maxHeight:480
						},
						option:[{
							souceId:videoSource,
							
						}],*/
						deviceId: videoSource ? { exact: videoSource } : undefined
					}
					
				};	


				await navigator.getUserMedia(constraints,onSuccess,onError);
				//await navigator.getUserMedia(constraints,onSuccess,onError);
				//await navigator.mediaDevices.getUserMedia(constraints,onSuccess,onError);
				/*await navigator.mediaDevices
				.getUserMedia(constraints)
				.then(onSuccess)
				.catch(onError)*/
			}
			

			/* function getCameras(sourceInfos)
			{
				for (var i=0;i!=sourceInfo.length;i++)
				{
					var souceInfo = sourceInfos[i];
					var option = document.createElement('option');
					option.value=souceInfo.id;
					if(souceInfo.kind=='video'){
						option.text=souceInfo.label||'camera '+(videoSelect.lengt1);
						videoSelect.appendChild(option);
					}
				}
			} */

			function getCameras()
			{
				//var isFirstCamer=false;
				navigator.mediaDevices.enumerateDevices()
				.then(devices => {
					devices.forEach(device => {
					if (device.kind === 'videoinput') {
						var option = document.createElement('option');
						console.log('Video device: ', device);
						option.text=device.label||'camera '+(videoSelect.length);
						option.value=device.deviceId;
						videoSelect.appendChild(option);
					} else if (device.kind === 'audioinput') {
						console.log('Audio device: ', device);
					}
					});
					console.log("get Camera List Done");
					startStream();
				})
				.catch(err => {
					console.error('Error enumerating devices: ', err);
				});
			}

			function onSuccess(stream){
				
				//stop old stream
				StopVideo();
				//stream.getTracks().forEach(function (track) { track.stop() })
				//start new stream
				localStream=stream;
				console.log("Success! We have a stream");
				//eprecated API
				//videoArea.src=window.URL.createObjectURL(stream);
				videoArea.srcObject=null;
				videoArea.srcObject = stream;
				//videoArea.className="grayscale_filter";	
				videoArea.play();
			}

			function onError(stream){
				constraints.log("Error with getUserMedia: ",error);
			}

			function StopVideo()
			{
				const video = document.querySelector('video');

				// A video's MediaStream object is available through its srcObject attribute
				const mediaStream = video.srcObject;
				if (mediaStream)
				{
					// Through the MediaStream, you can get the MediaStreamTracks with getTracks():
					const tracks = mediaStream.getTracks();
					//stop all like so:
					tracks.forEach(track => track.stop())
				}

				// navigator.mediaDevices.getUserMedia({video: true, audio: true})
				// .then(mediaStream => {
				// 	const stream = mediaStream;
				// 	const tracks = stream.getTracks();

				// 	//tracks[0].stop;
				// 	tracks.forEach(track => track.stop())
				// })
				
			}

			/* // stop both mic and camera
			function stopBothVideoAndAudio(stream) {
				stream.getTracks().forEach((track) => {
					if (track.readyState == 'live') {
						track.stop();
					}
				});
			}

			// stop only camera
			function stopVideoOnly(stream) {
				stream.getTracks().forEach((track) => {
					if (track.readyState == 'live' && track.kind === 'video') {
						track.stop();
					}
				});
			}

			// stop only mic
			function stopAudioOnly(stream) {
				stream.getTracks().forEach((track) => {
					if (track.readyState == 'live' && track.kind === 'audio') {
						track.stop();
					}
				});
			} */

			
		</script>
	</body>
</html>
